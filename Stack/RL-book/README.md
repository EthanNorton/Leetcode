# Reinforcement Learning Practice Problems

This repository contains LeetCode-style practice problems that align with concepts from "Reinforcement Learning: An Introduction" by Richard S. Sutton and Andrew G. Barto. Each chapter's problems are designed to help reinforce theoretical concepts through practical coding exercises.

## Table of Contents

### Chapter 1: Introduction
- Multi-armed Bandit Problems
- Exploration vs Exploitation Challenges
- Simple Agent-Environment Interactions

### Chapter 2: Multi-armed Bandits
- Implementing ε-greedy Strategy
- Upper Confidence Bound Algorithms
- Thompson Sampling Implementation
- Gradient Bandit Algorithms

### Chapter 3: Finite Markov Decision Processes
- State-Value Function Calculations
- Action-Value Function Implementation
- Policy Evaluation Problems
- Bellman Equation Applications

### Chapter 4: Dynamic Programming
- Policy Iteration Implementation
- Value Iteration Problems
- Asynchronous Dynamic Programming
- Gambler's Problem Implementation

### Chapter 5: Monte Carlo Methods
- First-Visit MC Prediction
- Every-Visit MC Implementation
- MC Control with Exploring Starts
- Off-Policy MC Control

### Chapter 6: Temporal-Difference Learning
- TD(0) Prediction Implementation
- SARSA Algorithm Problems
- Q-Learning Challenges
- Expected SARSA Implementation

### Chapter 7: n-step Bootstrapping
- n-step TD Prediction
- n-step SARSA
- Off-policy n-step SARSA
- n-step Tree Backup

### Chapter 8: Planning and Learning
- Dyna-Q Implementation
- Prioritized Sweeping
- Trajectory Sampling
- Real-time Dynamic Programming

### Chapter 9: On-policy Prediction with Approximation
- Gradient Monte Carlo
- Semi-gradient TD
- Feature Construction Problems
- Linear Function Approximation

### Chapter 10: On-policy Control with Approximation
- Episodic Semi-gradient SARSA
- Average Reward Problems
- Differential Semi-gradient SARSA
- Policy Gradient Methods

### Chapter 11: Off-policy Methods with Approximation
- Semi-gradient Off-policy TD
- Gradient TD Methods
- Emphatic TD Methods
- Proximal Policy Optimization

### Chapter 12: Eligibility Traces
- TD(λ) Implementation
- SARSA(λ) Problems
- True Online TD(λ)
- Watkins's Q(λ)

### Chapter 13: Policy Gradient Methods
- REINFORCE Algorithm Implementation
- Actor-Critic Methods
- Natural Policy Gradient
- Trust Region Policy Optimization

## How to Use This Repository

1. Each chapter folder contains:
   - Practice problems with increasing difficulty (Easy, Medium, Hard)
   - Example solutions in Python
   - Test cases to verify your implementation
   - Explanations linking theoretical concepts to practical implementation

2. Recommended approach:
   - Read the corresponding chapter in the textbook
   - Try solving the practice problems
   - Compare with example solutions
   - Run test cases to verify your implementation

3. Prerequisites:
   - Basic Python programming knowledge
   - Understanding of fundamental machine learning concepts
   - Familiarity with NumPy and basic linear algebra

## Contributing

Feel free to contribute by:
- Adding new practice problems
- Improving existing solutions
- Adding test cases
- Fixing bugs or improving documentation

## License

This repository is for educational purposes. All problems are original content while respecting the concepts from the textbook.
